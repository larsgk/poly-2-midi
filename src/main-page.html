<link rel="import" href="../bower_components/polymer/polymer-element.html">
<link rel="import" href="../bower_components/paper-button/paper-button.html">
<link rel="import" href="audio-mixin.html">
<link rel="import" href="virtual-keys.html">
<link rel="import" href="my-icons.html">

<dom-module id="main-page">
  <template>
    <style>
      :host {
        display: block;
        padding: 0;
        margin: 0;
      }
      .sampler {
        display:flex;
        flex-direction: column;
        width: 100%;
        max-width: 500px;
        margin-left: auto;
        margin-right: auto;
        justify-content:center;
        align-content: center;
      }
      
      #visualizer {
        display: block;
        width: 100%;
        height: 100px;
        margin: 0.5em 0 0;
      }

      virtual-keys {
        width: 100%;
        margin: 0.5em 0 0;
      }

      paper-button.record {
        color: var(--paper-red-500);
        font-size: 1.5em;
        margin: 0.5em auto 0;
        background-color: #fff;
      }
      paper-button.recording {
        color: #fff;
        background-color: var(--paper-red-500);
      }
      paper-button[disabled] {
        background-color: var(--paper-grey-200);
      }
    </style>

    <div class="sampler">
      <canvas id="visualizer"></canvas>
      <paper-button id="record" class="record" on-tap="_recordToggle"><iron-icon icon="[[recIcon(isRecording)]]"></iron-icon>[[recBtn(isRecording)]]</paper-button>
      <virtual-keys id="virtualKeys"></virtual-keys>
      Use a connected MIDI controller or the virtual keyboard (touch and keys)
      <template is="dom-repeat" items="[[eventlist]]">
        [[doRender(item)]]<br>
      </template>

    </div>
  </template>

  <script>
    class MainPage extends AudioMixin(Polymer.Element) {
      static get is() { return 'main-page'; }

      static get properties() {
        return {
          eventlist: {
            type: Array,
            value: () => []
          },
          midiaccess: {
            type: Object
          },
          isRecording: {
            type: Boolean,
            value: false
          }
        }
      }

      connectedCallback() {
        super.connectedCallback();
        requestAnimationFrame(this._init.bind(this));
      }

      _init() {
        const obj = document.createElement('audio');
        const canOgg = obj.canPlayType('audio/ogg');
        if(canOgg.length) {
          this.loadEffect('./sounds/flute1.ogg', 'sample')
        } else {
          // must make some mp3 for iOS ;)
        }

        if (navigator.requestMIDIAccess) {
            navigator.requestMIDIAccess({
                sysex: false
            }).then(midiaccess => {
                this.midiaccess = midiaccess;

                let inputs = this.midiaccess.inputs.values();
                for (let input = inputs.next(); input && !input.done; input = inputs.next()) {
                    console.log('midi input', input.value);
                    input.value.onmidimessage = this._onMIDIEvent.bind(this);
                }

                this.midiaccess.onstatechange = this._onMIDIStateChange.bind(this);
                
            },
            error => console.log("WindMIDIService error: " + error));
        } else {
             console.log("WindMIDIService error: WebMIDI not supported.");
        }

        const _KEY_NOTE = {
          "KeyQ":    60,
          "Digit2":  61,
          "KeyW":    62,
          "Digit3":  63,
          "KeyE":    64,
          "KeyR":    65,
          "Digit5":  66,
          "KeyT":    67,
          "Digit6":  68,
          "KeyY":    69,
          "Digit7":  70,
          "KeyU":    71,
          "KeyI":    72
        };

        // setup key bindings
        document.addEventListener('keydown', evt => {
          const toneDiff = Math.pow(2, 1/12);
          if(!evt.repeat) {
            const note = _KEY_NOTE[evt.code];
            if(note !== undefined) {
              this.playEffectNote('sample',Math.pow(toneDiff, note-60), note);
            } else if(evt.code === 'KeyS') {
              if(!this.$.record.disabled)
                this._recordToggle();
            }
          }
        });

        document.addEventListener('keyup', evt => {
          if(!evt.repeat) {
            const note = _KEY_NOTE[evt.code];
            if(note !== undefined) {
              this.stopNote(note);
            }
          }
        });

        this.$.virtualKeys.addEventListener('virtual-key',this._onVKEvent.bind(this));
        // setup recording...
        setTimeout(this._initRecording.bind(this), 500);
      }

      recBtn() {
        return this.isRecording ? "STOP (S)" : "SAMPLE (S)";
      }

      recIcon() {
        return this.isRecording ? "my-icons:stop" : "my-icons:fiber-manual-record";
      }

      _onMIDIEvent(event) {
        this._onMIDIMessage(event.data);
      }

      _onVKEvent(event) {
        //console.log(event);
        this._onMIDIMessage(event.detail);
      }

      _onMIDIMessage(data) {
        const toneDiff = Math.pow(2, 1/12);
        console.log(data);
        switch(data[0]) {
        case 144:
            if(data[2] > 0) {
                this.playEffectNote('sample',Math.pow(toneDiff, data[1]-60), data[1]);
            } else {
                this.stopNote(data[1]);
            }
            break;
        // case 0xE0: // 224 = pitch bend
        //     WindMIDIService._fireEvent({
        //         type: "pitch",
        //         value: data[1] + (data[2] << 7)
        //     });
        //     break;
        // case 0xD0: // 208 = pressure/after-touch
        //     WindMIDIService._fireEvent({
        //         type: "pressure",
        //         value: data[1]
        //     });
        //     break;

        }
      }

      _onMIDIStateChange(event) {
        console.log('midi state change: ', event);
        let port = event.port;
        if(port instanceof MIDIInput) {
          if(port.state === 'connected') {
            port.onmidimessage = this._onMIDIEvent.bind(this);
          }
        }
      }

      _initRecording() {
        if (navigator.getUserMedia) {
          let constraints = { audio: true, video: false };
          let chunks = [];

          let onSuccess = stream => {
            this.mediaRecorder = new MediaRecorder(stream, {mimeType: 'audio/webm'});

            this.visualize(stream);

            this.mediaRecorder.onstop = (e) => {
              var blob = new Blob(chunks, { 'type' : 'audio/webm' });
              chunks = [];

              this.loadEffectBlob(blob, 'sample')
              this.isRecording = false;
              // debounce a bit ;)
              setTimeout(() => {
                this.$.record.classList.remove('recording');
                this.$.record.disabled = false;
              }, 1000);
            }
          
            this.mediaRecorder.ondataavailable = (e) => {
              console.log(e.data);
              chunks.push(e.data);
            }
          }

          let onError = err => {
            console.log(err);
          }

          navigator.getUserMedia(constraints, onSuccess, onError);
        } else {
          console.log('getUserMedia is not supported!');
        }
      }

      _recordToggle() {
        if(this.mediaRecorder) {
          if(this.isRecording) {
            this.mediaRecorder.stop();
            this.$.record.disabled = true;
          } else {
            this.mediaRecorder.start();
            this.isRecording = true;
            this.$.record.classList.add('recording');
          }
        }
      }


      visualize(stream) {
        let audioCtx = new (window.AudioContext || webkitAudioContext)();

        let source = audioCtx.createMediaStreamSource(stream);

        let analyser = audioCtx.createAnalyser();
        analyser.fftSize = 2048;
        let bufferLength = analyser.frequencyBinCount;
        let dataArray = new Uint8Array(bufferLength);

        source.connect(analyser);
        //analyser.connect(audioCtx.destination);
        
        let canvas = this.$.visualizer;
        let WIDTH = canvas.width;
        let HEIGHT = canvas.height;
        let canvasCtx = canvas.getContext("2d");

        let draw = () => {

          requestAnimationFrame(draw);

          analyser.getByteTimeDomainData(dataArray);

          canvasCtx.fillStyle = '#0D47A1';
          canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

          canvasCtx.lineWidth = 2;
          canvasCtx.strokeStyle = '#E3F2FD';

          canvasCtx.beginPath();

          var sliceWidth = WIDTH * 1.0 / bufferLength;
          var x = 0;


          for(var i = 0; i < bufferLength; i++) {
      
            var v = dataArray[i] / 128.0;
            var y = v * HEIGHT/2;

            if(i === 0) {
              canvasCtx.moveTo(x, y);
            } else {
              canvasCtx.lineTo(x, y);
            }

            x += sliceWidth;
          }

          canvasCtx.lineTo(canvas.width, canvas.height/2);
          canvasCtx.stroke();

        }

        draw()
      }
  

    }
    window.customElements.define(MainPage.is, MainPage);
  </script>
</dom-module>
